---
title: About Me
---

Hey, my name is Roman Koshkin.

As a big AI enthusiast, I can't wait to see the next big thing in AI. I strongly believe that for any serious progress towards next-generation AI, we need to fixate less on backprop and instead try more to understand and reverse-engineer biological neural circuits. If you think this is an insane challenge, I agree. But it's worth the effort. To help make this a reality, I joined the <Link href="https://groups.oist.jp/ncbc">Neural Coding and Brain Computing Unit at OIST</Link>, where I am now investigating how the brain is able to learn so quickly and efficiently.

---

My recent research has been under the following themes:

- <b>Self-organized cell assemblies as a substrate of episodic memory</b>: Model of asscociative
  memory under a biologically-inspired STP-dependent symmetric STDP learning rule.
- <b>Sequence preplay for sample-efficient memory</b>: I am modeling how new episodes can be
  bootstrapped from preexisting topological and temporal structure of a contineously plastic binary
  neural network.
- <b>Role of spontaneous neural activity in memory</b>: Spontaneous neural activity in animals has
  been shown to reflect sensory priors. I aim to develop a biologically plausible simplified SNN
  model that can reliably store sensory priors and use them for task performance.

Before I joined the NCBC, I had spent four months at the Cognitive Neurorobotics Unit where I 'taught' a humanoid robot to perform a reach-and-grasp task by combining a limited set of learned motor primitives into diverse and novel motion trajectories. This work was inspired by the stochastic PV-RNN architecture.

As I am exploring this frontier as a scientist, I have several side projects (mostly in deep learning). I also like to [share](https://twitter.com) what my expertise in this area.

<RecipeReviewCard></RecipeReviewCard>
